{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TonpaZoldyck/Studies/blob/main/Group_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py3ghot99AhE"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YaFLUvk9AhI"
      },
      "source": [
        "We will beging by cleaning the data and checking for null values then we will explore the different variables to try to understand the data, identify different parameters and\n",
        "\n",
        "\n",
        "Sources: http://salserver.org.aalto.fi/opinnot/mat-2.4177/2018/McKinseyFinal.pdf\n",
        "\n",
        "https://escholarship.org/uc/item/9zg7157q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpeblRGU_NP1"
      },
      "outputs": [],
      "source": [
        "countryNo_referal = [\"Domican Republic\", \"England\"]\n",
        "countriesoneM_referal = [\"DRC\", \"England\"]\n",
        "vals = [\"Domican Republic\", \"DRC\"]\n",
        "Amnt = [100000, 100000]\n",
        "limit = 1000000\n",
        "refornot = []\n",
        "for i in range(len(vals)):\n",
        "  if vals[i] in countryNo_referal:\n",
        "    print(\"No Referal\")\n",
        "    refornot.append(\"No Referal\")\n",
        "  elif vals[i] in countriesoneM_referal and Amnt[i] < limit:\n",
        "    print(\"No Referal\")\n",
        "    refornot.append(\"No Referal\")\n",
        "  else:\n",
        "    print(\"Referal\")\n",
        "    refornot.append(\"Referal\")\n",
        "\n",
        "print(refornot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebaN10QJJWlH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUUJzFTI9AhJ"
      },
      "source": [
        "## 1. Data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzDNTt0t9AhK"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "import matplotlib.patches as mpatches\n",
        "import time\n",
        "\n",
        "# Classifier Libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import collections\n",
        "\n",
        "\n",
        "# Others\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import warnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICi6YDzTTl-o"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgYaPMJw-gue"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "train_data = pd.read_csv('default of credit card clients.csv', header = 0,\n",
        "                         index_col = 0)\n",
        "df=pd.DataFrame(train_data)\n",
        "# df.to_csv('default of credit card clients.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwie53PFWwZS"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsVSxBkl9AhO"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv('CreditCard_train.csv', header = 1)\n",
        "df.columns = [\"ID\", 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2',\n",
        "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
        "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
        "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', \"Default\"]\n",
        "df = df.drop(\"ID\", axis =1) # remove ID collumn has no predictive power"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr6rg3YF5f4t"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5MQHyeXA192"
      },
      "outputs": [],
      "source": [
        "df.columns, df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDSPWEcY9Aha"
      },
      "outputs": [],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKAJLojR9AhS"
      },
      "source": [
        "## 2. Data transformation and exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS_KVocy9Ahg"
      },
      "source": [
        "__2.1 Data Cleaning__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kStW1NWJ9Ahi"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum().max() # checking for null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAij9_6EElr1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "df.hist(figsize= (20,20)) #prelim look at distribution of data\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQsMqj3O5-K2"
      },
      "source": [
        "Fill in empty values for Marriage and Education"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkrcIGVV9Ahm"
      },
      "outputs": [],
      "source": [
        "## Data formating and preprocessing\n",
        "\n",
        "fil = (df.EDUCATION == 5) | (df.EDUCATION == 6) | (df.EDUCATION == 0) # change the extra values of education into other\n",
        "df.loc[fil, 'EDUCATION'] = 4\n",
        "df.EDUCATION.value_counts()\n",
        "\n",
        "\n",
        "\n",
        "df.loc[df.MARRIAGE == 0, 'MARRIAGE'] = 3 # change extra values of marrigage into other\n",
        "df.MARRIAGE.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vE2ZVNM9Ahz"
      },
      "outputs": [],
      "source": [
        "### Pay should integer values -1 to 9 excluding 0, seems that the -2 and 0 values have some meaning and are not mistaks as its unlikely that this many\n",
        "### are accidents,\n",
        "Pay1Default = pd.crosstab(index=df[\"Default\"],\n",
        "                            columns=df[\"PAY_1\"])\n",
        "Pay1Default\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3FnnUlo9Ah2"
      },
      "outputs": [],
      "source": [
        "df.groupby('PAY_1')['PAY_AMT1'].mean().plot(kind='bar')\n",
        "plt.show()\n",
        "## here we see the distribution of the PAY_1 variable based on the amount of people in each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ElzsIOeIiJ_"
      },
      "source": [
        "So the -2 Actually means that no consumption, 0 means use of revolving credit.\n",
        "\n",
        "Sources:http://inseaddataanalytics.github.io/INSEADAnalytics/CourseSessions/ClassificationProcessCreditCardDefault.html#a_process_for_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNYfnZMr9Ah-"
      },
      "source": [
        "__2.2 Data Exploration__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt4KNzqp9Ah_"
      },
      "outputs": [],
      "source": [
        "#finding the split of default vs non-default\n",
        "print('No Frauds', round(df['Default'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(df['Default'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ-ES0oQ9AiD"
      },
      "outputs": [],
      "source": [
        "# colors = [\"blue\", \"red\"]\n",
        "\n",
        "# sns.countplot(hue = 'Default', data=df, palette=colors)\n",
        "# plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbMKrsf09AiD"
      },
      "source": [
        "This is a reasonably balanced data set especially considering for most fraud detection cases data sets are heavily imbalanced\n",
        "\n",
        "Code Source: https://www.sciencedirect.com/science/article/pii/S0957417407006719"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1atitymr9Aia"
      },
      "source": [
        "__2.3 Grouping and analysis of different variabels__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bInBxXr9quNw"
      },
      "source": [
        "We decided to group similar types of variables and analyse them together. Here we saught to identify any correlations between the variabes and compare their distributions.\n",
        "We grouped them into demograhic variables, payment status and then bill and paid amount."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaiocWWc9Aib"
      },
      "outputs": [],
      "source": [
        "#Group the variables into similar or alike features to compare together\n",
        "demographic = ['SEX', 'EDUCATION', 'MARRIAGE','AGE']\n",
        "payment_status = [ 'PAY_1', 'PAY_2','PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
        "bill_amount = ['BILL_AMT1', 'BILL_AMT2','BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', \"LIMIT_BAL\"]\n",
        "paid_amount = [ 'PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6HXLH8a9Aif"
      },
      "outputs": [],
      "source": [
        "## Code adapted from Class notebooks\n",
        "\n",
        "df1 = df[demographic]\n",
        "scaler = StandardScaler() # we scaled the variables to compare their distributions\n",
        "df1 = scaler.fit_transform(df1)\n",
        "\n",
        "df1 = pd.DataFrame.from_records(df1)\n",
        "df1.plot.kde(legend = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFV-0y0J9Aij"
      },
      "outputs": [],
      "source": [
        "df1 = df[demographic]\n",
        "df1.plot(kind='density',subplots=True, layout=(3,2), sharex=False, sharey=False, figsize=(12, 8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOJUHLyv9Ain"
      },
      "outputs": [],
      "source": [
        "df1 = df[payment_status]\n",
        "scaler = StandardScaler()\n",
        "df1 = scaler.fit_transform(df1)\n",
        "\n",
        "df1 = pd.DataFrame.from_records(df1)\n",
        "df1.plot.kde()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgMwRsE99Ais"
      },
      "outputs": [],
      "source": [
        "df1 = df[payment_status]\n",
        "df1.plot(kind='density',subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=(12, 8))\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luxTrbAdsFXW"
      },
      "source": [
        "We see that the PAY variables have very similar almost identical distributions, this gives us an idea that we would not want to include all of them in our models as they are telling us the same things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA0Y5raH1Pyr"
      },
      "outputs": [],
      "source": [
        "df1 = df[bill_amount]\n",
        "scaler = StandardScaler()\n",
        "df1 = scaler.fit_transform(df1)\n",
        "\n",
        "df1 = pd.DataFrame.from_records(df1)\n",
        "df1.plot.kde()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AsQbxWe9Aiw"
      },
      "outputs": [],
      "source": [
        "df1 = df[bill_amount]\n",
        "df1.plot(kind='density',subplots=True, layout=(3,3), sharex=True, sharey=True, figsize=(12, 8))\n",
        "plt.show()\n",
        "# very similar distributions between pay_amt variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wgqHNL59Ai1"
      },
      "outputs": [],
      "source": [
        "df1 = df[paid_amount]\n",
        "df1.plot(kind='density',subplots=True, layout=(3,2), sharex=False, sharey=False, figsize=(12, 8))\n",
        "plt.show()\n",
        "# very similar distributions between pay_amt variables however limit_balance is quite different"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKJFZtBI1kiP"
      },
      "outputs": [],
      "source": [
        "df1 = df[paid_amount]\n",
        "scaler = StandardScaler()\n",
        "df1 = scaler.fit_transform(df1)\n",
        "\n",
        "df1 = pd.DataFrame.from_records(df1)\n",
        "df1.plot.kde()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPf6JRnAF681"
      },
      "source": [
        "**2.4 Data separability and Relationships**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB_X2EONtVuZ"
      },
      "source": [
        "Looking at the disrtibution and relationship between different continous variables with respect to Defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODZPhy6Z_t-h"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5)) # creates a figure with mutiple axes\n",
        "scatter = axes[0].scatter(df.AGE, df.LIMIT_BAL, c = df.Default) # plots axes one\n",
        "scatter1 = axes[1].scatter(df.AGE, df.PAY_AMT1,  c = df.Default)\n",
        "\n",
        "#creates legends\n",
        "legend1 = axes[0].legend(*scatter.legend_elements(),\n",
        "                    loc=\"upper right\", title=\"Default\")\n",
        "axes[0].add_artist(legend1)\n",
        "\n",
        "legend2 = axes[1].legend(*scatter1.legend_elements(),\n",
        "                    loc=\"upper right\", title=\"Default\")\n",
        "axes[1].add_artist(legend2)\n",
        "\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Pay Amount 1')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2MqkGgGs6Aa"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5)) # creates a figure with mutiple axes\n",
        "scatter = axes[0].scatter(df.LIMIT_BAL, df.PAY_AMT2, c = df.Default) # plots axes one\n",
        "scatter1 = axes[1].scatter(df.LIMIT_BAL, df.PAY_AMT3,  c = df.Default)\n",
        "\n",
        "legend1 = axes[0].legend(*scatter.legend_elements(),\n",
        "                    loc=\"upper left\", title=\"Default\") # creates legends\n",
        "axes[0].add_artist(legend1)\n",
        "\n",
        "legend2 = axes[1].legend(*scatter1.legend_elements(),\n",
        "                    loc=\"upper left\", title=\"Default\")\n",
        "axes[1].add_artist(legend2)\n",
        "\n",
        "plt.xlabel('Limit Balance')\n",
        "plt.ylabel('Pay Amount 3')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_7uMHgg5PZc"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5)) # creates a figure with mutiple axes\n",
        "scatter = axes[0].scatter(df.BILL_AMT1, df.PAY_AMT1, c = df.Default) # plots axes one\n",
        "scatter1 = axes[1].scatter(df.BILL_AMT3, df.PAY_AMT3,  c = df.Default)\n",
        "\n",
        "legend1 = axes[0].legend(*scatter.legend_elements(),\n",
        "                    loc=\"upper left\", title=\"Default\") # creates legends\n",
        "axes[0].add_artist(legend1)\n",
        "\n",
        "legend2 = axes[1].legend(*scatter1.legend_elements(),\n",
        "                    loc=\"upper left\", title=\"Default\")\n",
        "axes[1].add_artist(legend2)\n",
        "\n",
        "plt.xlabel('Bill Amount 3')\n",
        "plt.ylabel('Pay Amount 3')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnVwOfg7HYih"
      },
      "outputs": [],
      "source": [
        "groups = df.groupby('Default')\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots()\n",
        "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
        "for name, group in groups:\n",
        "    ax.plot(group.AGE, group.LIMIT_BAL, marker = '.', linestyle='', ms=7, label=name)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS1KiuXXtfbp"
      },
      "source": [
        "Looking at the spread and distribution of different data points with respect to defaults, We see that in 2D this data very diffcult to seperate suggesting using mutiple variables or Kernals can be a powerful technique.\n",
        "We also see that it is unilkey for the data to be linearly sepreable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzG5QldlEDOU"
      },
      "source": [
        "**2.5 Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP89nBVy9Ai5"
      },
      "outputs": [],
      "source": [
        "x1 = df.loc[df.Default==0, 'LIMIT_BAL']\n",
        "x2 = df.loc[df.Default==1 , 'LIMIT_BAL']\n",
        "\n",
        "# plot\n",
        "kwargs = dict(hist_kws={'alpha':.6}, kde_kws={'linewidth':2})\n",
        "\n",
        "plt.figure(figsize=(10,7), dpi= 80)\n",
        "sns.distplot(x1, color=\"blue\", label=\"Not Default\", **kwargs)\n",
        "sns.distplot(x2, color=\"red\", label=\"Default\", **kwargs)\n",
        "plt.xlim(-100000,1000000);\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW-yEHKN9Ai8"
      },
      "source": [
        "We see that here are some very extreme values, i.e customers will alot of money making very large payments, however, these are very few, most customers have much small payments.\n",
        "\n",
        "We see that there are very high defaults in the lower balance range suggesting that people who take out lower credit loans are more prone to default, we see that those who are able to take out much larger have a lower chance of defaulting. This makes some sense as very wealth clients are more able and thus more likely to pay their debts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlCv58M59AjE"
      },
      "outputs": [],
      "source": [
        "x1 = df.loc[df.PAY_1==2, 'AGE'] # creating different x variables to plot\n",
        "x2 = df.loc[df.PAY_1==1 , 'AGE']\n",
        "x3 = df.loc[df.PAY_1==-1 , 'AGE']\n",
        "x4 = df.loc[df.PAY_1==3 , 'AGE']\n",
        "\n",
        "\n",
        "# plot\n",
        "kwargs = dict(hist_kws={'alpha':.6}, kde_kws={'linewidth':2}) #used to format the plot\n",
        "\n",
        "plt.figure(figsize=(10,7), dpi= 80) # formating\n",
        "\n",
        "\n",
        "sns.distplot(x1, color=\"dodgerblue\", label=\"2 Months Late\", **kwargs) #plotting each variable\n",
        "sns.distplot(x2, color=\"orange\", label=\"1 Month late\", **kwargs)\n",
        "sns.distplot(x3, color=\"red\", label=\"Pay Duly\", **kwargs)\n",
        "sns.distplot(x4, color=\"blue\", label=\"3 Months Late\", **kwargs)\n",
        ";\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWn4rOmf9AjX"
      },
      "source": [
        "We see lots of differences between the Pay different values for the pay variable and age."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GZaEqt79Ai9"
      },
      "outputs": [],
      "source": [
        "#Looking at how age impacts defaults across its range\n",
        "x1 = df.loc[df.Default==0, 'AGE'] # defining each variable\n",
        "x2 = df.loc[df.Default==1 , 'AGE']\n",
        "\n",
        "# plot\n",
        "kwargs = dict(hist_kws={'alpha':.6}, kde_kws={'linewidth':2})\n",
        "\n",
        "plt.figure(figsize=(10,7), dpi= 80)\n",
        "sns.distplot(x1, color=\"blue\", label=\"Not Default\", **kwargs) #plotting the variables\n",
        "sns.distplot(x2, color=\"red\", label=\"Default\", **kwargs)\n",
        "plt.xlim(0,100);\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n7Mq0wn9AjB"
      },
      "source": [
        "Creating bins of the age variable rather than using the continous values may have more predicitve power. From the graph above we see that people within the age of 28 - 38 have are less likely to default. Otherwise both densities seem to trace each other. This suggests that using ranges could be a power way to unlock information for our models.\n",
        "\n",
        "Source:https://www.machinelearningplus.com/plots/matplotlib-histogram-python-examples/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK217UJv9AiH"
      },
      "outputs": [],
      "source": [
        "df['AGEBIN'] = 0 # creates empty column 1\n",
        "df.loc[((df['AGE'] > 18) & (df['AGE'] < 28)) , 'AGEBIN'] = 1 # defines the age range for catagory 1\n",
        "df.loc[((df['AGE'] >= 28) & (df['AGE'] < 38)) , 'AGEBIN'] = 2 # we want to capture the predictive power in this range\n",
        "df.loc[((df['AGE'] >= 38) & (df['AGE'] < 48)) , 'AGEBIN'] = 3\n",
        "df.loc[((df['AGE'] >= 48) & (df['AGE'] < 58)) , 'AGEBIN'] = 4\n",
        "df.loc[((df['AGE'] >= 58) & (df['AGE'] < 68)) , 'AGEBIN'] = 5\n",
        "df.loc[((df['AGE'] >= 68) & (df['AGE'] < 81)) , 'AGEBIN'] = 6 #this is the rest group for convience.\n",
        "df.AGEBIN.hist()\n",
        "## we will asses models using our feature and the standard age feature to see the difference if any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv1X76m-NTB2"
      },
      "source": [
        "From reading about credit card defaults we see that combinations of features maybe important. For example, combining marriage with sex, seeing how different combinations (e.g. married man, married women etc.) impact defaults\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydh1cTW3G0Nh"
      },
      "outputs": [],
      "source": [
        "df['MAR_SEX'] = df.SEX * df.MARRIAGE\n",
        "df.head()\n",
        "## this is an easy way of creating this variable\n",
        "# 1 = married man, 2 = divorced man, 3 = single man, 4 = married woman, 5 = divorced woman, 6 = single woman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAkCMNdlSvCW"
      },
      "outputs": [],
      "source": [
        "df.MAR_SEX.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLKgYE2wSd4_"
      },
      "source": [
        "In genral this method makes sense as from the literture we've analysed marriage has an impact on debts and defaults.\n",
        "\n",
        "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6045913/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYRoKYmO9AjY"
      },
      "source": [
        "## 3. Methodology Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt1QdOJm9AjZ"
      },
      "source": [
        "__3.1 Analaysing the importance of different variables__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgbjt91w9Ajb"
      },
      "source": [
        "This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
        "The Extra trees classfiier is a random forest technique that aggreates the results from different desciosn trees, each tree is provided with a random sample k of features, then the tree uses the Gini index to asses the information gain and form each node of the tree. This random sample of features leads to the creation of multiple de-correlated decision trees\n",
        "\n",
        "Source: https://www.geeksforgeeks.org/ml-extra-tree-classifier-for-feature-selection/\n",
        "\n",
        "Why extra trees not random forest?\n",
        "Extra trees perform better when there is more noisy in the data set and are quicker to run and less computationally expensive.\n",
        "Empircal research suggests that the optimal parameter for K is the sqrt(n) where n is the number of variables.\n",
        "\n",
        "Sources: https://orbi.uliege.be/bitstream/2268/9357/1/geurts-mlj-advance.pdf\n",
        "\n",
        "https://www.thekerneltrip.com/statistics/random-forest-vs-extra-tree/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lu9-oM5YWqd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, roc_curve, precision_recall_curve, confusion_matrix, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from pandas import read_csv\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_-Ch_HK9Ajb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "## Creating validation dataset\n",
        "X, y = df.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "\n",
        "# split the dataset into training and validation set\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=15)\n",
        "\n",
        "#Sclaing the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "\n",
        "K = [1,3,5,7,9,11,13, 15, 17, 19, 21 ,23, 25] #testing across the hyper paramter set\n",
        "accuracy, recall = [], []\n",
        "for i in K: # looping over each k and running the model to fine optimal point\n",
        "    model = ExtraTreesClassifier(random_state = i)\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred = model.predict(X_valid)\n",
        "    accuracyi = accuracy_score(y_valid, y_pred) # we also use accuracy to compare how measures perform\n",
        "    accuracy.append(accuracyi)\n",
        "    recalli = recall_score(y_valid, y_pred) # we focus on recall score as our main measure\n",
        "    recall.append(recalli)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSFa5_HO9Ajf"
      },
      "outputs": [],
      "source": [
        "plt.plot(K, recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49EXJkT89Ajk"
      },
      "outputs": [],
      "source": [
        "plt.plot(K, accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO5KpluX9Ajo"
      },
      "source": [
        "Using the validation dataset we see that based on these accuraicies and the recall we see that the optimal parameter for K is approximatiley 19 based on the empircal evidence we have observed.\n",
        "\n",
        "Code Sorucehttps://escholarship.org/uc/item/9zg7157q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE5yOrMM9Ajq"
      },
      "outputs": [],
      "source": [
        "## aassessing importance\n",
        "X, y = df.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "\n",
        "model = ExtraTreesClassifier(random_state = 19)\n",
        "model.fit(X,y)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(23).plot(kind='barh')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf9fFuVO9Ajx"
      },
      "source": [
        "__3.2 Feature Selection using Recrusive Feature elimination__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9rrJhAZ7Ksg"
      },
      "source": [
        "Here we use recursive feature selection using the random forrest model. This is where we run the model on the whole data set and the features are given a score in terms of how much they add to the model performace based on our scoring method recall. This method used cross validation to identfy important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFjfvx2X6MCL"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "## Creating validation dataset\n",
        "X, y = df.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "\n",
        "# split the dataset into training and validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wrn2wYd9Ajy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Feature Extraction with RFE\n",
        "\n",
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# Create a dataset with only 3 informative features\n",
        "\n",
        "# feature extraction\n",
        "#model = LogisticRegression(solver='lbfgs')\n",
        "model = RandomForestClassifier()\n",
        "cv =5\n",
        "rfe = RFECV(RandomForestClassifier(), cv=cv, scoring='recall')\n",
        "fit = rfe.fit(X, y)\n",
        "print(\"Num Features: %d\" % fit.n_features_)\n",
        "print(\"Selected Features: %s\" % fit.support_)\n",
        "print(\"Feature Ranking: %s\" % fit.ranking_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB68hAEj9Aj2"
      },
      "outputs": [],
      "source": [
        "# adds the chosen features into a list\n",
        "features = []\n",
        "for i in range(23):\n",
        "    if fit.support_[i] == True:\n",
        "        features.append(df.columns[i])\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGnLIJv99Aj9"
      },
      "source": [
        "__3.3 Feature filtering using variable correlation__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jwmvCTBGCFp"
      },
      "outputs": [],
      "source": [
        "corrmat = df.corr()\n",
        "fig = plt.figure(figsize = (12,9))\n",
        "sns.heatmap(corrmat, vmax = .8, square = True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RQ8n4Ai9AiL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "X, y = df.drop(\"Default\", axis=1), df[\"Default\"].copy()   #target column i.e price range\n",
        "#get correlations of each features in dataset\n",
        "corrmat = df.corr()\n",
        "top_corr_features = corrmat.index\n",
        "plt.figure(figsize=(20,20))\n",
        "#plot heat map\n",
        "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6X8kqCV9AiO"
      },
      "source": [
        "Code Source: https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e\n",
        "\n",
        "Genrally we don't want to include two variables that are highly correlated as the information gained from adding the extra variable is low and thus we risk over fitting.\n",
        "We see that there is high correlation between the different Bill and Pay variables, which suggests that including all of them in our models may lead to overfitting.\n",
        "\n",
        "We also see a weak negative correlation between the pay variables and the Limit balance.\n",
        "\n",
        "The created variables are highly correlated with their incumbent variables which makes sense as such when modelling we would like to only include only one variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqD-eZyi9AkB"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# goes through the variables and identfies which features should be removed based on being correlated\n",
        "correlated_features = set()\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "for i in range(len(correlation_matrix .columns)):\n",
        "    for j in range(i):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > 0.6:\n",
        "            colname = correlation_matrix.columns[i]\n",
        "            correlated_features.add(colname)\n",
        "print(correlated_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Pxry7D9AkH"
      },
      "source": [
        "This is in line with the correlation plot and the importance ranking we have previously. As we see the bills terms are all very highly correlated to one another and so to are the Pay terms suggesting that whislt there may be information gain from having one of them, as suggested by the variable importance analysis, incorporating them all adds little value to the model and likely only leads to higher risk of overfitting.\n",
        "Source: https://stackabuse.com/applying-filter-methods-in-python-for-feature-selection/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgwVXe29AkI"
      },
      "source": [
        "__3.4 Feature Selection using Lasso__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9KjG4SVYjuF"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "X, y = df.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "\n",
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n",
        "X_train.shape, X_test.shape\n",
        "#scale data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train.fillna(0))\n",
        "\n",
        "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2'))\n",
        "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)\n",
        "\n",
        "sel_.get_support()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu2lrpeKYu5v"
      },
      "outputs": [],
      "source": [
        "selected_feat = X_train.columns[(sel_.get_support())]\n",
        "print('total features: {}'.format((X_train.shape[1])))\n",
        "print('selected features: {}'.format(len(selected_feat)))\n",
        "print('features with coefficients shrank to zero: {}'.format(\n",
        "      np.sum(sel_.estimator_.coef_ == 0)))\n",
        "print(selected_feat)\n",
        "## PAY_6 was removed by the Lasso suggesting that this feature isn't as important as the rest when it comes to predictive power and modelling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMzeB1HrdHtL"
      },
      "source": [
        "Combining these different feature selections we come to some important conclusions. Firstly, from the descion tree importance we see that variables PAY_1, LIMIT_BAL, and AGE are very important when it comes to these models. We also see that other variables such as bil amt and pay amt have predtive power.\n",
        "\n",
        "We have also identfied correlated variables, these are ones we'd like to remove as they don't add much information and likely lead to overfitting as we would be fitting the noise of each variable, with out really adding much to the signal.\n",
        "Recursive feature selection also supports our conlusions. Using mutiple different feature selection methods makes us less bias to one method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4j-J7btef3b"
      },
      "outputs": [],
      "source": [
        "## Important features\n",
        "features1 = ['MARRIAGE', 'PAY_1', 'BILL_AMT1', 'PAY_AMT1', \"AGE\", \"LIMIT_BAL\", \"SEX\"] # with orignal features\n",
        "features2 = ['MAR_SEX', 'PAY_1', 'BILL_AMT1', 'PAY_AMT1', \"AGEBIN\", \"LIMIT_BAL\", ] # with new created features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcXqix7G9AkM"
      },
      "source": [
        "## 4. Model Training and Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl8sGAFqJYVw"
      },
      "source": [
        "__4.1 Original features__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZDU9gX_9AkO"
      },
      "source": [
        "We'll use a basic Logistic regression with all the features as our basic model and then compare the performacnes of these based on our main performace metric Recall.\n",
        "For this particular data set it make sense to use recall as our primary performance measure, as if we look at it from the banks perspetive, more money is lost when the model predicts that someone will not default and they do as the bank won't receive its loaned money."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7o4ucXW9Akw"
      },
      "source": [
        "The random forrest algorithm is a very powerful predictor, in genral what it does is aggerate the predictions of n different descison trees and uses this as it predictor. The reason why this concpet works is that if the different predictors are uncorrelated than then an aggeration of the trees should mean that some trees remove or cancel out some of the errors made by other trees, i.e overfitting the data.\n",
        "\"A larger number of uncorrelated models (trees) operating as a committee will outperfomr any indivdual consitient model.\"\n",
        "A random forrest uses a technique called bagging, where the we look at the prediction made by each indivdual tree and then use a majority voting function to make the prediction for the particular case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELjLuhlA003I"
      },
      "source": [
        "For tuning the SVM we can expect and see from our data exploration that its not likely that the data is linearly sperable, thus we opt to using either a guassian (RBF) or a polynomial kernal to map our SVM to higher dimensions. When tunning the SVM there was two key hyper paramters we need to tune. C this is the pentaly for misclassifcation, and can be see as a meaure of the complexity of the model the higher C is the more the model penalises misclassified data, a very high C will lead to overfitting as the model trys to avoid misclassifcation at all costs. The second hyperparamter we need to tune is gamma. Gamma is the spread of the kernal. It is the hyper paramter for the guassian Kernal and is used to handle non-linear data. The idea is that a larger gamma has a close reach where as low values mean far reach. This means that if gamma is large only points near the descion boundry are taken into account, where as when gamma is small points further away are taken into account. Thus, really high value of gamma can lead to over-fitting as the model trys to perfectly seperate the data. A very low value of gamma can mean high bias, thus underfitting as it will make the descion boundry more linear and more smooth boundry as it incorprates data that is further away.\n",
        "Sources: https://chrisalbon.com/machine_learning/support_vector_machines/svc_parameters_using_rbf_kernel/\n",
        "https://www.youtube.com/watch?v=m2a2K4lprQw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UdvZ68Af_0N"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
        "from statistics import mean\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXauYYkbSNwm"
      },
      "outputs": [],
      "source": [
        "#random state\n",
        "state = 1\n",
        "#outlier detection methods\n",
        "classifiers = {'Random Forest Classifier': RandomForestClassifier(random_state = state),\n",
        "               'Support Vector Machine': SVC(random_state = state),\n",
        "               'Logistic Regression': LogisticRegression()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI1niAS1ao2A"
      },
      "source": [
        "Here we loop over our chosen algorithms and tune use gridsearch to tune the hyperparameters. The scoring method we use is recall as this is the one that would be most relvant to the bang. Recall takes into account false negatives, i.e when the algorithm predicts someone will not default but the infact do. This is important as this is likely where the bank would lose the most money as it won't recived back the money it loaned out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_3WXq6J6_UA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c365de-cd32-40b1-d1ae-9c928bcd4f71"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF\n",
            "{'criterion': 'entropy', 'max_depth': 20, 'max_features': 'auto', 'n_estimators': 150}\n",
            "SVC\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features1] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
        "    #fit the data and tag outliers\n",
        "    if clf_name == 'Random Forest Classifier':\n",
        "      model = RandomForestClassifier(random_state = state)\n",
        "      param_grid = {'n_estimators': [50, 100, 150, 200], 'max_features': ['auto', 'log2'],  'max_depth': [  13, 17 ,20], 'criterion': ['gini', 'entropy']}\n",
        "        # Combine the parameter sets with the defined model\n",
        "      print(\"RF\")\n",
        "      CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
        "        # Fit the model to our training data and obtain best parameters\n",
        "      CV_model.fit(X, y)\n",
        "      print(CV_model.best_params_)\n",
        "    elif clf_name == 'Support Vector Machine':\n",
        "      model = SVC(random_state = state)\n",
        "      param_grid = [{'kernel': ['rbf'], 'gamma': [0.001, 0.1],'C': [10, 100, 200]},\n",
        "                    {'kernel': ['poly'], 'C': [1, 10, 100], 'degree': [1,2,5]}]\n",
        "        # Combine the parameter sets with the defined model\n",
        "      print(\"SVC\")\n",
        "      CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='recall', n_jobs=-1)\n",
        "        # Fit the model to our training data and obtain best parameters\n",
        "      CV_model.fit(X, y)\n",
        "      print(CV_model.best_params_)\n",
        "\n",
        "\n",
        "    else:\n",
        "      model = LogisticRegression()\n",
        "      param_grid = {'penalty': ['l1', 'l2'],'C':[0.001,0.01,1,10,25]}\n",
        "        # Combine the parameter sets with the defined model\n",
        "      print(\"LR\")\n",
        "      CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
        "        # Fit the model to our training data and obtain best parameters\n",
        "      CV_model.fit(X, y)\n",
        "      print(CV_model.best_params_)\n",
        "## notes even though the SVC takes a while to run i think including more paramters is a good idea as we don't know if a large C is better or a smaller gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5f-wxbxbgcG"
      },
      "source": [
        "We then use the tuned paramters and run these models on the datset with our chosen features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuPkeNE4fm1t"
      },
      "source": [
        "__4.2 With Feature Set 2__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6M2fuXrfMBh"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "####\n",
        "## we tested it and the hyper paramters are the same for both sets of features no need to paramterise them again.\n",
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features2] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
        "    #fit the data and tag outliers\n",
        "    if clf_name == 'Random Forest Classifier':\n",
        "      model = RandomForestClassifier(random_state = state)\n",
        "      param_grid = {'n_estimators': [50, 100, 150, 200], 'max_features': ['auto', 'log2'],  'max_depth': [ 9, 11, 13], 'criterion': ['gini', 'entropy']}\n",
        "      print('RF')\n",
        "        # Combine the parameter sets with the defined model\n",
        "      CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
        "        # Fit the model to our training data and obtain best parameters\n",
        "      CV_model.fit(X, y)\n",
        "      print(CV_model.best_params_)\n",
        "    elif clf_name == 'Logistic Regression':\n",
        "      model = LogisticRegression()\n",
        "      param_grid = {'penalty': ['l1', 'l2'],'C':[0.001,0.01,1,10,25]}\n",
        "        # Combine the parameter sets with the defined model\n",
        "      print(\"LR\")\n",
        "      CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
        "        # Fit the model to our training data and obtain best parameters\n",
        "      CV_model.fit(X, y)\n",
        "      print(CV_model.best_params_)\n",
        "\n",
        "    else:\n",
        "      model = SVC(random_state = state)\n",
        "      param_grid = [{'kernel': ['rbf'], 'gamma': [0.001, 0.1],'C': [50, 100]},\n",
        "                    {'kernel': ['poly'], 'C': [ 10], 'degree': [1,5]}]\n",
        "      print('SVC')\n",
        "        # Combine the parameter sets with the defined model\n",
        "      CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
        "        # Fit the model to our training data and obtain best parameters\n",
        "      CV_model.fit(X, y)\n",
        "      print(CV_model.best_params_)\n",
        "## notes even though the SVC takes a while to run i think including more paramters is a good idea as we don't know if a large C is better or a smaller gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y70g03cau-J7"
      },
      "outputs": [],
      "source": [
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features1] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfQQ3c2dt554"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "clf = SVC(kernel='rbf', random_state=state, gamma=1, C=100)\n",
        "## around 100 probaly best from playing around with it\n",
        "y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "print(accuracy_score(y, y_pred))\n",
        "print(recall_score(y,y_pred))\n",
        "\n",
        "\n",
        "confusion_plot(y,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQi6qjCf9Anq"
      },
      "source": [
        "## 5. Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MatPFSzRgdtW"
      },
      "source": [
        "Now we will run other tuned models on the validation set to see how well they perform and see if any improvements can be made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg7tXPOxxeu4"
      },
      "source": [
        "__5.1 With Standard Features__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHlPLIbskzZe"
      },
      "outputs": [],
      "source": [
        "##imports\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SplgpX7Zie-t"
      },
      "outputs": [],
      "source": [
        "## to plot the confusion matrcies\n",
        "\n",
        "def confusion_plot(y_test, y_pred) :\n",
        "    labels = [0, 1]\n",
        "    cm = confusion_matrix(y_test, y_pred, labels)\n",
        "    print(cm)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    #cax = ax.matshow(cm, cmap = 'viridis' )\n",
        "    cax = ax.matshow(cm, cmap = 'Reds' )\n",
        "    plt.title('Confusion matrix of the classifier')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticklabels([''] + labels)\n",
        "    ax.set_yticklabels([''] + labels)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    return plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fafa1pzKjuam"
      },
      "outputs": [],
      "source": [
        "Greens#fit the model with tuned hyperparameters\n",
        "\n",
        "#using tuned hyperparameters\n",
        "state = 1\n",
        "#outlier detenction methods\n",
        "classifiers = {'Random Forest Classifier': RandomForestClassifier(criterion = 'entropy', max_depth = 13, max_features = 'auto', n_estimators = 100, random_state = state),\n",
        "               'Support Vector Machine': SVC(C = 100, gamma = 0.1, kernel = 'rbf', random_state = state),\n",
        "               'Naive Bayes': GaussianNB(),\n",
        "               'Logistic Regression': LogisticRegression(C= 1, penalty = 'l1')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "968GhVcclLvS"
      },
      "outputs": [],
      "source": [
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features1] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7pTWkHXjwSK"
      },
      "outputs": [],
      "source": [
        "#for our modeling we also want to use cross validation\n",
        "#n_outliers = len(fraud)\n",
        "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
        "    #fit the data and tag outliers\n",
        "    if clf_name == 'Random Forest Classifier':\n",
        "        clf.fit(X, y)\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "    elif clf_name == 'Support Vector Machine':\n",
        "        clf.fit(X, y)\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "    elif clf_name == 'Logistic Regression':\n",
        "        clf.fit(X, y)\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "\n",
        "    else:\n",
        "        clf.fit(X, y)\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "\n",
        "\n",
        "\n",
        "    n_errors = (y_pred != y).sum()\n",
        "\n",
        "    #run classification metrics\n",
        "    print('{}: {}'.format(clf_name, n_errors))\n",
        "    print(accuracy_score(y, y_pred))\n",
        "    print(recall_score(y,y_pred))\n",
        "    print(classification_report(y, y_pred))\n",
        "    confusion_plot(y,y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9504jn9VMVoi"
      },
      "source": [
        "__5.2 With Engineered features__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugoXvTbfelOt"
      },
      "outputs": [],
      "source": [
        "#fit the model with tuned hyperparameters\n",
        "\n",
        "#using tuned hyperparameters\n",
        "state = 1\n",
        "#outlier detenction methods\n",
        "classifiers = {'Random Forest Classifier': RandomForestClassifier(criterion = 'entropy', max_depth = 13, max_features = 'auto', n_estimators = 100, random_state = state),\n",
        "               'Support Vector Machine': SVC(C = 100, gamma = 0.1, kernel = 'rbf', random_state = state),\n",
        "               'Naive Bayes': GaussianNB(),\n",
        "               'Logistic Regression': LogisticRegression(C= 1, penalty = 'l1')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdAmeXG6dY6T"
      },
      "outputs": [],
      "source": [
        "#for our modeling we also want to use cross validation\n",
        "#n_outliers = len(fraud)\n",
        "\n",
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features2] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
        "    #fit the data and tag outliers\n",
        "    if clf_name == 'Random Forest Classifier':\n",
        "        clf.fit(X, y)\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "\n",
        "    elif clf_name == 'Support Vector Machine':\n",
        "        clf.fit(X, y)\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "    elif clf_name == 'Logistic Regression':\n",
        "        clf.fit(X, y)\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "\n",
        "    else:\n",
        "        clf.fit(X, y)\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=5)\n",
        "\n",
        "    n_errors = (y_pred != y).sum()\n",
        "\n",
        "    #run classification metrics\n",
        "    print('{}: {}'.format(clf_name, n_errors))\n",
        "    print(accuracy_score(y, y_pred))\n",
        "    print(recall_score(y,y_pred))\n",
        "    print(classification_report(y, y_pred))\n",
        "    confusion_plot(y,y_pred)\n",
        "result_table.set_index('classifiers', inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV_xNt-GF95k"
      },
      "source": [
        "When comparing the two feature sets we see that our engineered features only perform slightly better on the models than the normal features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k7wGPE49Alj"
      },
      "source": [
        "__5.3 Ensemble Method__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UMU2NllizYU"
      },
      "source": [
        "The Ensemble model we have chosen is stacking. This is where we take the algorithms that we run previous and combine them together to create one ensemble model. Stacking is where the base algorithms in our case LR, SVC and GNB are all trained on the whole training dataset. Then the preditions from these are used to on the meta-classifer which uses the predictions of these other classifiers to then predict the data. Genrally, an ensemble will outperform the indivdual models used to create it however, this is not guaranted. We have chosen to stack at 2 levels as the more levels you have the smaller the data you get to train on which could become an issue at higher levels.\n",
        "\n",
        "Sources: https://blog.statsbot.co/ensemble-learning-d1dcd548e936"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bew1SFA-OdcG"
      },
      "outputs": [],
      "source": [
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features2] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvp0voxy9Alu"
      },
      "outputs": [],
      "source": [
        "state = 1\n",
        "models = [\n",
        "    SVC(C = 100, gamma = 0.1, kernel = 'rbf', random_state = state),\n",
        "    LogisticRegression(C= 1, penalty = 'l1'),\n",
        "    GaussianNB()\n",
        "]\n",
        "\n",
        "#performs better than the classifier than includes knn in terms of recall, accuracy is similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P28WBYxb_-v"
      },
      "outputs": [],
      "source": [
        "!pip install -q vecstack\n",
        "from vecstack import stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NhwFkva9Aly"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "S_train, S_test = stacking(models, X_train, y_train, X_test, regression=False, mode='oof_pred_bag', needs_proba=False,\n",
        "\n",
        "save_dir=None, metric=recall_score, n_folds=5, stratified=True,shuffle=True,  random_state=0, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YblERma39AmB"
      },
      "source": [
        "Source: https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKxNnBlU9AmC"
      },
      "outputs": [],
      "source": [
        "\n",
        "model =  RandomForestClassifier(criterion = 'entropy', max_depth = 13, max_features = 'auto', n_estimators = 100, random_state = state)\n",
        "\n",
        "\n",
        "\n",
        "En_model = model.fit(S_train, y_train)\n",
        "En_y_pred = model.predict(S_test)\n",
        "\n",
        "\n",
        "#lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
        "#lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
        "\n",
        "print('Final Accuracy score: [%.8f]' % accuracy_score(y_test, En_y_pred))\n",
        "print('Final Recall score: [%.8f]' % recall_score(y_test, En_y_pred))\n",
        "confusion_plot(y_test, En_y_pred)\n",
        "### Scores with SVC as meta classifier: 0.81750000, 0.32116105\n",
        "### Scores with NB as meta classifier: 0.81833333, 0.32677903\n",
        "### Scores with LR as meta classifier: 0.81666667, 0.31086142\n",
        "### Scores with RF as meta classifier: 0.80833333, 0.37734082\n",
        "### Scores Meta classifer = XGB, all models:0.81750000, 0.32116105\n",
        "## The best in terms of recall for our meta classifier is the RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfDb68OqLHka"
      },
      "outputs": [],
      "source": [
        "print('Final Accuracy score: [%.8f]' % accuracy_score(y_test, En_y_pred))\n",
        "print('Final Recall score: [%.8f]' % recall_score(y_test, En_y_pred))\n",
        "confusion_plot(y_test, En_y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5916mDZgsQe"
      },
      "source": [
        "We ran our ensemble with different meta-classifers each time and noted down the accuracy and recall produced, we see that the best meta classifier for our model is the random forrest interms of recall performance, accuracy remains quite consistent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU1msG5JUu2W"
      },
      "source": [
        "__5.4 Preicsion Recall Curves__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm_2WY_wW_iD"
      },
      "source": [
        "https://classeval.wordpress.com/introduction/introduction-to-the-precision-recall-plot/\n",
        "Why Precison Recall curves are better for imbalanced data.\n",
        "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPSNpS4d4bOS"
      },
      "source": [
        "Since SVM is a discrimant classification techique it does not directly learn proabilites, however, these can be estimated where the output from the SVC is taken and a cross validated logistic regression is used to output the probailites for the predictions that this SVM model makes. Since the SVM doesnt out put its own proabilites these are just estimates and thus are less reliable.\n",
        "Source: https://chrisalbon.com/machine_learning/support_vector_machines/calibrate_predicted_probabilities_in_svc/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtZ75MERX-V4"
      },
      "outputs": [],
      "source": [
        "pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVN-yHgDXz_Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "#from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import auc\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.pyplot import figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba6MU6wH5xaA"
      },
      "outputs": [],
      "source": [
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features2] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)\n",
        "plot_RP(X_train, y_train, X_test, y_test, classifiers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlCxemPgweMs"
      },
      "outputs": [],
      "source": [
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features1] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkS4B_ffvmP_"
      },
      "outputs": [],
      "source": [
        "\n",
        "classifiers = {'Random Forest Classifier': RandomForestClassifier(criterion = 'entropy', max_depth = 13, max_features = 'auto', n_estimators = 100, random_state = state),\n",
        "               'Support Vector Machine': SVC(C = 100, gamma = 0.1, kernel = 'rbf', random_state = state, probability = True),\n",
        "               'Naive Bayes': GaussianNB(),\n",
        "               'Logistic Regression': LogisticRegression(C= 1, penalty = 'l1'),\n",
        "               'ensemble': RandomForestClassifier(criterion = 'entropy', max_depth = 13, max_features = 'auto', n_estimators = 100, random_state = state) }\n",
        "\n",
        "\n",
        "\n",
        "figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
        "def plot_RP (X_train, y_train, X_test, y_test, classifiers):\n",
        "  for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
        "    if clf_name == \"ensemble\":\n",
        "      state = 1\n",
        "      models = [ LogisticRegression(C= 1, penalty = 'l1'), GaussianNB(),SVC(C = 100, gamma = 0.1, kernel = 'rbf', random_state = state)]\n",
        "      S_train, S_test = stacking(models, X_train, y_train, X_test, regression=False, mode='oof_pred_bag', needs_proba=False,\n",
        "                                 save_dir=None, metric=recall_score, n_folds=5, stratified=True,shuffle=True,  random_state=0, verbose=2)\n",
        "      model = clf.fit(S_train, y_train)\n",
        "      y_pred = model.predict(S_test)\n",
        "      lr_probs = model.predict_proba(S_test)\n",
        "      lr_probs = lr_probs[:, 1]\n",
        "      yhat = model.predict(S_test)\n",
        "\n",
        "\n",
        "      lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
        "      #lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
        "\n",
        "    else:\n",
        "      model = clf\n",
        "      model.fit(X_train, y_train)\n",
        "      lr_probs = model.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "      lr_probs = lr_probs[:, 1]\n",
        "      # predict class values\n",
        "      yhat = model.predict(X_test)\n",
        "      lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
        "      # summarize scores\n",
        "\n",
        "    # plot the precision-recall curves\n",
        "    kwargs={'linewidth':1}\n",
        "    pyplot.plot(lr_recall, lr_precision, marker=',', label=clf_name, **kwargs)\n",
        "    # axis labels\n",
        "    pyplot.xlabel('Recall')\n",
        "    pyplot.ylabel('Precision')\n",
        "    # show the legend\n",
        "    pyplot.legend()\n",
        "  no_skill = len(y_test[y_test==1]) / len(y_test)\n",
        "  pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "  return pyplot.show()\n",
        "plot_RP(X_train, y_train, X_test, y_test, classifiers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pm5lQ1_UoRt"
      },
      "source": [
        "__ROC Curves__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oOFaAgtvZfG"
      },
      "outputs": [],
      "source": [
        "def plot_ROC(result_table):\n",
        "  fig = plt.figure(figsize=(10,8))\n",
        "  for i in result_table.index: plt.plot(result_table.loc[i]['fpr'], result_table.loc[i]['tpr'], label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
        "  plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "  plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "  plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
        "\n",
        "  plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "  plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "  plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "  plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "  return plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5Po4InzBXPk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# Instantiate the classfiers and make a list\n",
        "classifiers = [RandomForestClassifier(criterion = 'entropy', max_depth = 13, max_features = 'auto', n_estimators = 100, random_state = state),\n",
        "               GaussianNB(),  LogisticRegression(C= 1, penalty = 'l1'), SVC(C = 100, gamma = 0.1, kernel = 'rbf', random_state = state, probability = True)]\n",
        "\n",
        "# Define a result table as a DataFrame\n",
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
        "\n",
        "# Train the models and record the results\n",
        "for cls in classifiers:\n",
        "    model = cls.fit(X_train, y_train)\n",
        "    yproba = model.predict_proba(X_test)[::,1]\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
        "    auc = roc_auc_score(y_test, yproba)\n",
        "\n",
        "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
        "                                        'fpr':fpr,\n",
        "                                        'tpr':tpr,\n",
        "                                        'auc':auc}, ignore_index=True)\n",
        "\n",
        "# Set name of the classifiers as index labels\n",
        "result_table.set_index('classifiers', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uet6QYchCTZn"
      },
      "outputs": [],
      "source": [
        "plot_ROC(result_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEI2LzYMCaCx"
      },
      "source": [
        "Source: https://abdalimran.github.io/2019-06-01/Drawing-multiple-ROC-Curves-in-a-single-plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CA57p0Hewla"
      },
      "source": [
        "## Final Predications on Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf8ebqGWcP8m"
      },
      "source": [
        "Here we will compare the performance of our tuned models on the test data set, and see how this compares to the validation set. We will explore potential reasons behind the conclusions and present them in a user-friendly way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMPahwFGc3Oe"
      },
      "outputs": [],
      "source": [
        "### imports\n",
        "import io\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6k5r4D79Ans"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(io.BytesIO(uploaded['CreditCard_test.csv']), header=1)\n",
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5FTMYfa85mS"
      },
      "outputs": [],
      "source": [
        "data = df\n",
        "X, y = data.drop(\"Default\", axis=1), df[\"Default\"].copy()\n",
        "X = X[features2] #first set of chosen features\n",
        "\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6emAjbvcPNW"
      },
      "outputs": [],
      "source": [
        "test_data.columns = [\"ID\", 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2',\n",
        "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
        "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
        "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', \"Default\"]\n",
        "\n",
        "\n",
        "test_data = test_data.drop(\"ID\", axis =1) # remove ID collumn has no predictive power\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6W0TcNj7Bqk"
      },
      "outputs": [],
      "source": [
        "##Replace extra values in the education field with 4 i.e other catgory as there is no 5 or 6\n",
        "\n",
        "fil = (test_data.EDUCATION == 5) | (test_data.EDUCATION == 6) | (test_data.EDUCATION == 0)\n",
        "test_data.loc[fil, 'EDUCATION'] = 4\n",
        "test_data.EDUCATION.value_counts()\n",
        "\n",
        "\n",
        "## As for marriage values of 0 can be changed to 3 i.e other.\n",
        "test_data.loc[test_data.MARRIAGE == 0, 'MARRIAGE'] = 3\n",
        "test_data.MARRIAGE.value_counts()\n",
        "\n",
        "## As for marriage values of 0 can be changed to 3 i.e other.\n",
        "test_data.loc[test_data.MARRIAGE == 0, 'MARRIAGE'] = 3\n",
        "test_data.MARRIAGE.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ks2wKF89Nm7"
      },
      "outputs": [],
      "source": [
        "df1 = test_data\n",
        "df1['AGEBIN'] = 0\n",
        "df1.loc[((df1['AGE'] > 18) & (df1['AGE'] < 28)) , 'AGEBIN'] = 1\n",
        "df1.loc[((df1['AGE'] >= 28) & (df1['AGE'] < 38)) , 'AGEBIN'] = 2 # we want to capture the predictive power in this range\n",
        "df1.loc[((df1['AGE'] >= 38) & (df1['AGE'] < 48)) , 'AGEBIN'] = 3\n",
        "df1.loc[((df1['AGE'] >= 48) & (df1['AGE'] < 58)) , 'AGEBIN'] = 4\n",
        "df1.loc[((df1['AGE'] >= 58) & (df1['AGE'] < 68)) , 'AGEBIN'] = 5\n",
        "df1.loc[((df1['AGE'] >= 68) & (df1['AGE'] < 81)) , 'AGEBIN'] = 6 #this is the rest group for convience.\n",
        "\n",
        "df1['MAR_SEX'] = df1.SEX * df1.MARRIAGE\n",
        "df1.head()\n",
        "df1.AGEBIN.hist()\n",
        "## we will asses models using our feature and the standard age feature to see the difference if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqBLFHEy6ZcR"
      },
      "outputs": [],
      "source": [
        "data = df1\n",
        "X_test, y_test = data.drop(\"Default\", axis=1), data[\"Default\"].copy()\n",
        " #first set of chosen features\n",
        "X_test = X_test[features2]\n",
        "#scale features\n",
        "scaler = StandardScaler()\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwkY0LgV6vws"
      },
      "outputs": [],
      "source": [
        "models = [RandomForestClassifier(criterion = 'entropy', max_depth = 8, max_features = 'auto', n_estimators = 150, random_state = state),\n",
        "               GaussianNB(),  LogisticRegression(C= 1, penalty = 'l1'), SVC(C = 100, gamma = .1, kernel = 'rbf', random_state = state)]\n",
        "\n",
        "\n",
        "for i in models:\n",
        "  model = i\n",
        "  model.fit(X,y)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Recall: % 5.6f, Accuracy : % 5.6f\" %(recall_score(y_test, y_pred), accuracy_score(y_test, y_pred)))\n",
        "  print(\"Precision: % 5.6f, F1_Score : % 5.6f\" %(precision_score(y_test, y_pred), f1_score(y_test, y_pred)))\n",
        "  confusion_plot(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxzub9jfNKw6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}